# backend/main.py

import torch
import torch.nn as nn

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import numpy as np
import os

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì •ì˜
from openai import OpenAI

# PositionalEncoding ë° SignLanguageTransformer í´ë˜ìŠ¤ ì •ì˜
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=500):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        pos = torch.arange(0, max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-torch.log(torch.tensor(10000.0)) / d_model))
        pe[:, 0::2] = torch.sin(pos * div_term)
        pe[:, 1::2] = torch.cos(pos * div_term)
        self.register_buffer("pe", pe.unsqueeze(0))

    def forward(self, x):
        return x + self.pe[:, :x.size(1)]

class SignLanguageTransformer(nn.Module):
    def __init__(self, input_dim=274, d_model=384, nhead=8, num_layers=8, num_classes=980, dropout=0.1):
        super().__init__()
        self.input_proj = nn.Linear(input_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dropout=dropout,
            batch_first=True,
            norm_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.dropout = nn.Dropout(dropout)
        self.classifier = nn.Sequential(
            nn.LayerNorm(d_model), # LayerNormì˜ ì…ë ¥/ì¶œë ¥ ì°¨ì›ì€ d_modelê³¼ ê°™ìŠµë‹ˆë‹¤.
            nn.Linear(d_model, num_classes)
        )

    def forward(self, x):  # x: (B, T, input_dim)
        # ì´ forward í•¨ìˆ˜ëŠ” 274 ì°¨ì› ì…ë ¥ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
        B, T, _ = x.shape
        x = self.input_proj(x)  # (B, T, d_model)
        x = self.pos_encoder(x)
        x = self.transformer(x)  # (B, T, d_model)
        x = self.dropout(x.mean(dim=1))  # (B, d_model) # ì‹œí€€ìŠ¤ì˜ í‰ê· ì„ ì‚¬ìš©
        return self.classifier(x)


app = FastAPI()

class SignLanguageRequest(BaseModel):
    keypoints_sequence: List[List[float]]
    relationships: List[str]

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def convert_tone(text: str, relationship: str) -> str:
    prompt = f'"{text}"ë¼ëŠ” ë¬¸ì¥ì„ "{relationship}" ê´€ê³„ì— ë§ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ë¡œ ë°”ê¿”ì¤˜.'
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role":"system","content":"ë„ˆëŠ” ê´€ê³„ì— ë§ëŠ” ë§íˆ¬ë¥¼ ë§Œë“¤ì–´ ì¤˜."},{"role":"user","content":prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except:
        return text

# ëª¨ë¸ ë¡œë“œ
script_dir = os.path.dirname(__file__)

# PyTorch ëª¨ë¸ ë° í´ë˜ìŠ¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •
model_file_name = "best_model_3e_flip_more_0.899.pt"
classes_file_name = "sign_keypoints.npz" # í´ë˜ìŠ¤ íŒŒì¼ ì´ë¦„ì´ PyTorch í•™ìŠµ ì‹œì™€ ë™ì¼í•œì§€ í™•ì¸ í•„ìš”

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
project_root = os.path.abspath(os.path.join(script_dir, ".."))
pytorch_model_path = os.path.join(project_root, "ì¸ì‹O_í‚¤í¬ì¸íŠ¸_ì „ë¶€", model_file_name)
pytorch_classes_path = os.path.join(project_root, "models", classes_file_name) # ê°€ì •: classes íŒŒì¼ì€ models ë””ë ‰í† ë¦¬ì— ìˆìŒ

try:
    # PyTorch ëª¨ë¸ ë¡œë“œ
    # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì €ì¥ëœ ëª¨ë¸ì˜ ì‹¤ì œ ì•„í‚¤í…ì²˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
    model = SignLanguageTransformer(input_dim=274, d_model=384, num_layers=8, nhead=8, num_classes=980)
    # ëª¨ë¸ ìƒíƒœ ì‚¬ì „ ë¡œë“œ
    checkpoint = torch.load(pytorch_model_path, map_location=torch.device('cpu'))
    model.load_state_dict(checkpoint)
    model.eval() # í‰ê°€ ëª¨ë“œ

    # í´ë˜ìŠ¤ ë¡œë“œ (ê¸°ì¡´ numpy íŒŒì¼ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    classes_data = np.load(pytorch_classes_path, allow_pickle=True)
    classes = classes_data["classes"] if "classes" in classes_data else classes_data["arr_0"] # .npz íŒŒì¼ êµ¬ì¡°ì— ë”°ë¼ í‚¤ ì¡°ì •

    print(f"âœ… PyTorch ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {pytorch_model_path}")
    print(f"âœ… í´ë˜ìŠ¤ ë¡œë“œ ì„±ê³µ: {pytorch_classes_path}, í´ë˜ìŠ¤ ìˆ˜: {len(classes)}")

except Exception as e:
    print(f"âŒ ëª¨ë¸ ë˜ëŠ” í´ë˜ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
    model = None
    classes = []

# sequence_lengthëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€
sequence_length = 259

@app.post("/predict")
async def predict_sign_language(request: SignLanguageRequest):
    if model is None:
        raise HTTPException(status_code=500, detail="ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜")
    # í‚¤í¬ì¸íŠ¸ ì°¨ì› í™•ì¸ (í”„ë ˆì„ë‹¹ 150 ì°¨ì›) - ëª¨ë¸ì€ 274 ì°¨ì› ê¸°ëŒ€. ì—¬ê¸°ì„œ ë¶ˆì¼ì¹˜ ë°œìƒ.
    # í˜„ì¬ëŠ” ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë§ì§€ ì•Šìœ¼ë©´ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ)
    # TODO: í‚¤í¬ì¸íŠ¸ ì°¨ì› ë¶ˆì¼ì¹˜ (150 vs 274) ì²˜ë¦¬ ë¡œì§ ì¶”ê°€ (ì˜ˆ: 150 -> 274 ë³€í™˜)
    if len(request.keypoints_sequence) == 0 or (len(request.keypoints_sequence) > 0 and len(request.keypoints_sequence[0]) != 150):
         print(f"âš ï¸ ê²½ê³ : ìˆ˜ì‹ ëœ í‚¤í¬ì¸íŠ¸ í”„ë ˆì„ ì°¨ì›ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: 150, ìˆ˜ì‹ : {len(request.keypoints_sequence[0]) if len(request.keypoints_sequence) > 0 else 0}")
         return {"predicted_class": "ì²˜ë¦¬ì¤‘...", "probability": 0.0, "converted_text": "ì²˜ë¦¬ì¤‘..."}

    # ì‹œí€€ìŠ¤ ê¸¸ì´ í™•ì¸
    if len(request.keypoints_sequence) != sequence_length:
         print(f"âš ï¸ ê²½ê³ : ìˆ˜ì‹ ëœ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤. ì˜ˆìƒ: {sequence_length}, ìˆ˜ì‹ : {len(request.keypoints_sequence)}")
         # ì„ì‹œë¡œ ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
         # TODO: ì‹œí€€ìŠ¤ ê¸¸ì´ ë¶ˆì¼ì¹˜ ì‹œ íŒ¨ë”©/ì˜ë¼ë‚´ê¸° ë¡œì§ ì¶”ê°€
         return {"predicted_class": "ì²˜ë¦¬ì¤‘...", "probability": 0.0, "converted_text": "ì²˜ë¦¬ì¤‘..."}


    # PyTorch ëª¨ë¸ ì…ë ¥ í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ë³€í™˜ (Batch_size, Sequence_length, Input_dim)
    # ëª¨ë¸ì€ 274 ì°¨ì› ì…ë ¥ì„ ê¸°ëŒ€í•˜ì§€ë§Œ, í˜„ì¬ 150 ì°¨ì›ë§Œ ìˆ˜ì‹ ë¨.
    # ì´ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ 274 ì°¨ì›ìœ¼ë¡œ ë§ì¶°ì•¼ í• ì§€ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    # ì„ì‹œë¡œ 150 ì°¨ì› ë°ì´í„°ë¥¼ 274 ì°¨ì›ìœ¼ë¡œ 'í™•ì¥'í•˜ëŠ” ê°„ë‹¨í•œ ì²˜ë¦¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. (ì •í™•í•œ ë°©ë²•ì€ ì•„ë‹˜)
    # ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” í•™ìŠµì— ì‚¬ìš©ëœ 274ì°¨ì› í‚¤í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜, 150ì°¨ì›ì— ë§ê²Œ ëª¨ë¸ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    padded_data = []
    for frame_keypoints in request.keypoints_sequence:
        # 150 ì°¨ì› í‚¤í¬ì¸íŠ¸ ë’¤ì— 0ìœ¼ë¡œ ì±„ì›Œì„œ 274 ì°¨ì›ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
        padded_frame = frame_keypoints + [0.0] * (274 - 150)
        padded_data.append(padded_frame)

    data = torch.tensor(padded_data, dtype=torch.float32).unsqueeze(0) # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

    with torch.no_grad(): # ì¶”ë¡  ì‹œì—ëŠ” grad ê³„ì‚° ì•ˆ í•¨
        pred = model(data) # ëª¨ë¸ ì˜ˆì¸¡

    # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
    prob = torch.softmax(pred, dim=1) # í™•ë¥  ê³„ì‚°
    idx = int(torch.argmax(prob, dim=1).item()) # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤

    if not classes or idx < 0 or idx >= len(classes):
         sign = "ì•Œ ìˆ˜ ì—†ìŒ"
         predicted_probability = 0.0
    else:
         sign = classes[idx]
         predicted_probability = float(prob[0][idx].item())

    # ê´€ê³„ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ GPT ë³€í™˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    rel = request.relationships[0] if request.relationships else "ìƒëŒ€"
    conv_text = convert_tone(sign, rel)

    # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
    print(f"ğŸ“¥ /predict ìš”ì²­ ìˆ˜ì‹ . ì‹œí€€ìŠ¤ ê¸¸ì´: {len(request.keypoints_sequence)}, ê´€ê³„: {request.relationships}, ì²« í”„ë ˆì„ ì°¨ì›: {len(request.keypoints_sequence[0]) if len(request.keypoints_sequence) > 0 else 0}")
    print(f"ğŸ“Š ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼: í´ë˜ìŠ¤={sign}, í™•ë¥ ={predicted_probability:.4f}")
    print(f"ğŸ—£ï¸ GPT ë³€í™˜ ê²°ê³¼: {conv_text}")


    return {"predicted_class": sign, "probability": predicted_probability, "converted_text": conv_text}

@app.get("/")
def root():
    return {"message": "ìˆ˜ì–´ ì¸ì‹ + GPT API"}
