# realtime_infer_transformer_resized.py

import cv2
import torch
import json
import numpy as np
from collections import deque

import mediapipe as mp

# â”€â”€ í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ import â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from models import SignTransformer     # models.py ì•ˆì— ì •ì˜ëœ ëª¨ë¸
from preprocess import extract_keypoints  # preprocess.py ì•ˆì— ìˆëŠ” í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_label_map(path="label_map.json"):
    with open(path, 'r', encoding='utf-8') as f:
        label_map = json.load(f)
    idx2label = {v: k for k, v in label_map.items()}
    return label_map, idx2label

def main():
    ###############################################
    # 1) ì„¤ì •ê°’ ì •ì˜
    ###############################################
    SEQ_LEN        = 64
    INPUT_DIM      = 1662
    LABEL_MAP_PATH = "label_map.json"
    CKPT_PATH      = "best_model_fold1_0.8861.pt"
    DEVICE         = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

    # (A) ëª¨ë¸ ì¶”ë¡ ìš© í•´ìƒë„ (extract_keypointsëŠ” 224Ã—224 ì˜ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì •)
    VIS_W, VIS_H = 224, 224

    # (B) í™”ë©´ ì¶œë ¥ìš© í•´ìƒë„ (ì›í•˜ë©´ ë” í¬ê²Œ)
    DISPLAY_W, DISPLAY_H = 1080, 810

    # (C) FRAME_SKIP ì„¤ì •: ní”„ë ˆì„ë§ˆë‹¤ extract_keypoints í˜¸ì¶œ
    FRAME_SKIP = 2

    # â”€â”€ MediaPipe Holistic ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mp_holistic = mp.solutions.holistic.Holistic(
        static_image_mode=False,
        model_complexity=1,
        enable_segmentation=False,
        refine_face_landmarks=True,
        min_detection_confidence=0.3,
        min_tracking_confidence=0.3
    )
    mp_draw = mp.solutions.drawing_utils
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # â”€â”€ DrawingSpec ì •ì˜ (ì ê³¼ ì„ ì„ ì‘ê²Œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pose_lm_style   = mp_draw.DrawingSpec(color=(0,255,0), thickness=1, circle_radius=1)
    pose_conn_style = mp_draw.DrawingSpec(color=(0,200,0), thickness=1)

    hand_lm_style   = mp_draw.DrawingSpec(color=(0,128,255), thickness=1, circle_radius=1)
    hand_conn_style = mp_draw.DrawingSpec(color=(0,128,200), thickness=1)

    face_lm_style   = mp_draw.DrawingSpec(color=(255,0,128), thickness=1, circle_radius=1)
    face_conn_style = mp_draw.DrawingSpec(color=(200,0,80), thickness=1)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # â”€â”€ ì›¹ìº  ì—´ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("ERROR: ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # â”€â”€â”€ ë²„í¼ ë° ìƒíƒœ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    frame_buffer = deque(maxlen=SEQ_LEN)  # 64ì¥ ì¶”ë¡ ìš© ì˜ìƒ(224Ã—224)
    raw_buffer   = deque(maxlen=SEQ_LEN)  # 64ì¥ raw í‚¤í¬ì¸íŠ¸(1662 dim ì „ì²˜ë¦¬ ì „)
    seq_active   = False
    pred_buffer  = deque(maxlen=10)
    sentence     = []
    last_word    = None
    repeat_cnt   = 0
    frame_count  = 0
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # â”€â”€ ë ˆì´ë¸”ë§µ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    label_map, idx2label = load_label_map(LABEL_MAP_PATH)
    NUM_CLASSES = len(label_map)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # â”€â”€ SignTransformer ëª¨ë¸ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    model = SignTransformer(
        num_classes=NUM_CLASSES,
        input_dim=INPUT_DIM,
        # ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ d_model=128, nhead=8, nlayers=3 ì‚¬ìš©
    ).to(DEVICE)
    state = torch.load(CKPT_PATH, map_location=DEVICE)
    model.load_state_dict(state)
    model.eval()
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    with torch.no_grad():
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # 1) ë’¤ì§‘ê¸°, BGRâ†’RGB
            frame = cv2.flip(frame, 1)
            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # 2) ëª¨ë¸ ì¶”ë¡ ìš© ë¦¬ì‚¬ì´ì¦ˆ (224Ã—224)
            small = cv2.resize(img_rgb, (VIS_W, VIS_H))
            draw_frame = cv2.cvtColor(small, cv2.COLOR_RGB2BGR)

            # 3) MediaPipe Holistic ì‹¤í–‰
            res = mp_holistic.process(small)

            # 4) ëœë“œë§ˆí¬ ì‹œê°í™” (ì‘ì€ í•´ìƒë„ì—ì„œ)
            if res.pose_landmarks:
                mp_draw.draw_landmarks(
                    draw_frame,
                    res.pose_landmarks,
                    mp.solutions.holistic.POSE_CONNECTIONS,
                    landmark_drawing_spec=pose_lm_style,
                    connection_drawing_spec=pose_conn_style
                )
            if res.left_hand_landmarks:
                mp_draw.draw_landmarks(
                    draw_frame,
                    res.left_hand_landmarks,
                    mp.solutions.holistic.HAND_CONNECTIONS,
                    landmark_drawing_spec=hand_lm_style,
                    connection_drawing_spec=hand_conn_style
                )
            if res.right_hand_landmarks:
                mp_draw.draw_landmarks(
                    draw_frame,
                    res.right_hand_landmarks,
                    mp.solutions.holistic.HAND_CONNECTIONS,
                    landmark_drawing_spec=hand_lm_style,
                    connection_drawing_spec=hand_conn_style
                )
            if res.face_landmarks:
                mp_draw.draw_landmarks(
                    draw_frame,
                    res.face_landmarks,
                    mp.solutions.holistic.FACEMESH_TESSELATION,
                    landmark_drawing_spec=face_lm_style,
                    connection_drawing_spec=face_conn_style
                )

            # 5) â€œraw í‚¤í¬ì¸íŠ¸â€ë§Œ ë½‘ì•„ì„œ raw_bufferì— ì €ì¥
            pts = []
            # (A) PoseLandmarks (33Ã—4)
            for i in range(33):
                if res.pose_landmarks and len(res.pose_landmarks.landmark) > i:
                    p = res.pose_landmarks.landmark[i]
                    pts.extend([p.x, p.y, p.z, p.visibility])
                else:
                    pts.extend([0.0, 0.0, 0.0, 0.0])
            # (B) Left hand (21Ã—3)
            for i in range(21):
                if res.left_hand_landmarks and len(res.left_hand_landmarks.landmark) > i:
                    p = res.left_hand_landmarks.landmark[i]
                    pts.extend([p.x, p.y, p.z])
                else:
                    pts.extend([0.0, 0.0, 0.0])
            # (C) Right hand (21Ã—3)
            for i in range(21):
                if res.right_hand_landmarks and len(res.right_hand_landmarks.landmark) > i:
                    p = res.right_hand_landmarks.landmark[i]
                    pts.extend([p.x, p.y, p.z])
                else:
                    pts.extend([0.0, 0.0, 0.0])
            # (D) Face landmarks (468Ã—3)
            for i in range(468):
                if res.face_landmarks and len(res.face_landmarks.landmark) > i:
                    p = res.face_landmarks.landmark[i]
                    pts.extend([p.x, p.y, p.z])
                else:
                    pts.extend([0.0, 0.0, 0.0])

            raw_buffer.append(np.array(pts, dtype=np.float32))

            # 6) ëª¨ë¸ ì¶”ë¡ ìš© ì˜ìƒ(224Ã—224)ë„ frame_bufferì— ì €ì¥
            frame_buffer.append(draw_frame.copy())

            # 7) ì˜ˆì¸¡ í™œì„±í™” ìƒíƒœì—ì„œë§Œ ë™ì‘
            if seq_active and len(raw_buffer) == SEQ_LEN:
                # FRAME_SKIPë§ˆë‹¤ í•œ ë²ˆì”©ë§Œ extract_keypoints í˜¸ì¶œ
                if frame_count % FRAME_SKIP == 0:
                    frames_list = list(frame_buffer)         # 64ì¥ Ã— (224Ã—224 BGR)
                    kp_seq = extract_keypoints(frames_list)  # ë°˜í™˜: (64,1662)

                    x = torch.from_numpy(kp_seq).unsqueeze(0).to(DEVICE)  # (1,64,1662)
                    logits = model(x)  # (1, NUM_CLASSES)
                    pred_idx = logits.argmax(dim=1).item()
                    word = idx2label[pred_idx]

                    pred_buffer.append(word)
                    if word == last_word:
                        repeat_cnt += 1
                    else:
                        repeat_cnt = 0
                        last_word = word

                    if repeat_cnt >= 3:
                        if len(sentence) == 0 or sentence[-1] != word:
                            sentence.append(word)
                        repeat_cnt = 0

                #  í™”ë©´ ì¢Œìƒë‹¨ì— í˜„ì¬ ì˜ˆì¸¡ ë‹¨ì–´ ê·¸ë¦¬ê¸°
                cv2.putText(
                    draw_frame,
                    f"{last_word}",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1.0,
                    (0, 255, 0),
                    2
                )

            # 8) ëˆ„ì  ë¬¸ì¥(ìµœê·¼ 7ë‹¨ì–´) í‘œì‹œ
            cv2.putText(
                draw_frame,
                " ".join(sentence[-7:]),
                (10, 80),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,
                (0, 255, 0),
                2
            )

            # 9) ì œì–´ ì•ˆë‚´ ë¬¸êµ¬
            if seq_active:
                cv2.putText(
                    draw_frame,
                    "[ACTIVE] Press 'e' to pause, 'c' to clear, 'q' to quit",
                    (10, VIS_H - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (200, 200, 200),
                    2
                )
            else:
                cv2.putText(
                    draw_frame,
                    "Press 's'=start, 'e'=pause, 'c'=clear, 'q'=quit",
                    (10, VIS_H - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (200, 200, 200),
                    2
                )

            # 10) í™”ë©´ ì—…ìŠ¤ì¼€ì¼: 224Ã—224 â†’ DISPLAY_WÃ—DISPLAY_H (ì˜ˆ: 640Ã—480)
            display_frame = cv2.resize(draw_frame, (DISPLAY_W, DISPLAY_H))
            cv2.imshow("Real-time Sign Translation", display_frame)

            frame_count += 1

            # 11) í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord("q"):
                break
            elif key == ord("s"):
                seq_active = True
                frame_buffer.clear()
                raw_buffer.clear()
                pred_buffer.clear()
                sentence.clear()
                last_word = None
                repeat_cnt = 0
                print("ğŸŸ¢ ì˜ˆì¸¡ ì‹œì‘!")
            elif key == ord("e"):
                seq_active = False
                print("â›” ì˜ˆì¸¡ ì¼ì‹œì •ì§€")
            elif key == ord("c"):
                sentence.clear()
                print("ğŸ§¹ ë¬¸ì¥ ì´ˆê¸°í™”ë¨")

    cap.release()
    cv2.destroyAllWindows()
    mp_holistic.close()

if __name__ == "__main__":
    main()
